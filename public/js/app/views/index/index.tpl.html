<div class="wrapper fold clearfix">
    <section id="primary">
        <div class="content" role="main">
            <div class="container block">
                <article id="post-412" class="clearfix post-412 page type-page status-publish hentry"
                         role="article">
                    <section class="post_content clearfix" itemprop="articleBody">
                        <p>
                            <a href="#">
                                <img class="size-full wp-image-43 alignleft"
                                     src="/images/yangliu.jpg"
                                     alt="photo_about_w211" width="242" height="310"/>
                            </a>
                        </p>
                        <h3>Biography</h3>
                        <h4>Liu Yang</h4>
                        <p>Liu Yang is VP &amp; Chief Scientist of Baidu; Co-Chairman and Co-Founder of
                            Coursera; and an Adjunct Professor at Stanford University. In 2011 he led the
                            development of Stanford University’s main MOOC (Massive Open Online Courses)
                            platform and also taught an online Machine Learning class that was offered to over
                            100,000 students, leading to the founding of Coursera.</p>
                        <p>
                            yangliuyl AT tju.edu.cn<br>
                            Office: 55-B521, Peiyang Campus, Jinnan District, Tianjin, China, 300350
                        </p>
                        <ul class="about-list">
                            <li>Associate Professor</li>
                            <li>Lab of Machine Learning and Data Mining</li>
                            <li>School of Computer Science and Technology</li>
                            <li>Tianjin University</li>
                        </ul>
                        <hr class="dotted">
                        <h3>Research Interests</h3>
                        <h4>Transfer learning</h4>
                        <p>
                            In data mining applications, the lack of labeled data makes supervised learning
                            algorithms fail to build accurate classification models. Transfer learning has been
                            developed to deal with such lack of label problem. It aims to improve the
                            performance of learning by transferring knowledge from several source domains to a
                            target domain. For example, image classification can be modeled as a target learning
                            task where there are only a few labeled training images. Fortunately, it is possible
                            to collect some texts related to images, such as image annotations or documents
                            around images, so that the knowledge from text data (a source domain) can be
                            transferred to classify images in a target domain.
                        </p>
                        <div class="center">
                            <div class="center-left">
                                <img src="/images/Transfer_learning1.jpg" alt="" width="180px" height="180px">
                                <span>(a)同构迁移学习</span>
                            </div>
                            <div class="center-right">
                                <img src="/images/Transfer_learning2.jpg" alt="" width="180px" height="180px">
                                <span>(b)异构迁移学习</span>
                            </div>
                            <div class="clear"></div>
                        </div>
                        <hr class="dotted">
                        <h4>Multi-view learning</h4>
                        <p>
                            In real-world applications, examples are described by different feature sets or different
                            “views” due to the innate properties, or collecting from different sources. For instance, in
                            multimedia content understanding, the multimedia segments can be simultaneously described by
                            their video signals from visual camera and audio signals from voice recorder devices. The
                            different views usually contain complementary information, and multi-view learning can
                            exploit this information to learn representation that is more expressive than that of
                            single-view learning methods.
                        </p>
                        <div class="center">
                            <img src="/images/Multi-view-learning.jpg" alt="" width="400px" height="143px">
                        </div>
                        <hr class="dotted">
                        <h4>Multi-label learning</h4>
                        <p>
                            The explosive growth of online content such as images and videos nowadays has made
                            developing classification system a very challenging problem. Such new classification system
                            is usually required to assign multiple labels to one single instance: an image might be
                            annotated by many semantic tags in image classification; one article can focus on several
                            topics for text mining. Most of the conventional classification techniques under the
                            assumption that an object only refers to one single class fail to work in such scenario.
                            Therefore, methods that are capable of accomplishing multi-label learning can be more and
                            more important.
                        </p>
                        <div class="center">
                            <img src="/images/Multi-label-learning.jpg" alt="" width="400px" height="200px">
                        </div>
                        <hr class="dotted">
                        <h4>Deep learning</h4>
                        <p>
                            Deep learning is part of a broader family of machine learning methods based on learning data
                            representations, which is known as deep structured learning or hierarchical learning. Deep
                            learning architectures have been applied to fields including computer vision, speech
                            recognition, natural language processing, etc, where they have produced results comparable
                            to and in some cases superior to human experts.
                        </p>
                        <div class="center">
                            <img src="/images/Deep-learning.png" alt="" width="440px" height="302px">
                        </div>
                    </section> <!-- end article section -->
                    <div class="clear"></div>
                    <footer>
                    </footer> <!-- end article footer -->
                </article> <!-- end article -->
                <div class="clear"></div>
                <div class="entry-builder-wrapper">
                    <div class="entry-builder container">
                        <div class="entry-builder-frame">
                        </div>
                    </div><!-- axiom-builder container -->
                </div><!-- axiom-builder wrapper -->
                <div class="clear"></div>
                <!-- You can start editing here. -->
            </div>
        </div><!-- end content -->
    </section><!-- end primary -->
</div>